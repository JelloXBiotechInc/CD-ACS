{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a990088-1326-4877-81bc-c8804c6864c1",
   "metadata": {},
   "source": [
    "# CDACS Model Experiment - Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8410f42c-82f6-42e4-8b47-7267a6e4b133",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd5b0f3-05fe-4469-8c61-9cc4ecc14aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "physical_devices = tf.config.list_physical_devices('GPU') \n",
    "for device in physical_devices:\n",
    "    tf.config.experimental.set_memory_growth(device, True)\n",
    "physical_devices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f94c4cd-04d2-4652-90ae-dac7f735ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b736ae25-edb8-4e84-b7c9-87738b2532fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from module.model_utils import *\n",
    "from module.metrics import *\n",
    "from module.dataset_utils import BasicDatasetProcess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4001875-e865-4824-97da-554636291b82",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Import datasets and examine details from output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79790235-0370-48f2-b1c0-b614c0d037fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.camelyon16\n",
    "\n",
    "dataset_wrappers_he = BasicDatasetProcess.get_dataset_wrapper_from_dataset('camelyon16', 'HE_CR')\n",
    "\n",
    "dataset_wrappers_he"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9ea2b87-8069-4c69-88d0-4842d54b9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets.fluorescence\n",
    "\n",
    "dataset_wrappers_if = BasicDatasetProcess.get_dataset_wrapper_from_dataset('fluorescence', 'IF_CR')\n",
    "\n",
    "dataset_wrappers_if"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3aabd-c0c7-43e2-97be-c13ac318e853",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Preprocessing datasets using Color Deconvolution(CD) algorithm in the batch-processed manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943b7fc6-4afa-4425-a0f0-c2d381029b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "he_test = dataset_wrappers_he['test'].process()\n",
    "if_test = dataset_wrappers_if['test'].process()\n",
    "\n",
    "he_test, if_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362437e2-7b0b-41b1-81f7-da6f1b506966",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Setup UNet + MobileNetV2 hybrid model for 1024 input size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94580c4-be75-4559-b88e-4e7a9699ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patch_size=1000\n",
    "input_size=1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabf240d-86a9-47e3-881d-1aaec063efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_obj = MobileNetV2_1024_Model(\n",
    "    output_channels=2,\n",
    "    input_channels=1,\n",
    "    input_size=input_size,\n",
    ")\n",
    "model = model_obj.model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=[\n",
    "                  'accuracy',\n",
    "                  jacard_coef,\n",
    "                  dice_coef,\n",
    "              ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc00cca-42b6-43c5-87ea-137185233f92",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load CDACS model best checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a84735-4eca-4ed7-aafa-516c087c1a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_path = '/path/to/your/weight.hdf5'\n",
    "model.load_weights(weight_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a2e2a7-2b08-4b1e-ab52-e9ad258a1225",
   "metadata": {},
   "source": [
    "## Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1934431f-d142-4038-8c2c-71635182c703",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Pre-defined necessary paths and functions to generate result images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe23c05-7308-47c1-a9bf-7239fb6fd743",
   "metadata": {},
   "outputs": [],
   "source": [
    "def large_prediction(image, mask, cr_mask=None, patch_size=patch_size):\n",
    "    pred_mask = model_obj.easy_predict_single(image, patch_size=patch_size, batch_size=2)\n",
    "    \n",
    "    pp_pred_mask = np.array(pred_mask, dtype=bool)\n",
    "    if cr_mask != None:\n",
    "        cr_mask = np.array(cr_mask.numpy(), dtype=bool)\n",
    "        pp_pred_mask = np.logical_and(pp_pred_mask, cr_mask)\n",
    "    \n",
    "    fig = display(\n",
    "        [image, mask, pred_mask, pp_pred_mask],\n",
    "        show=False,\n",
    "        # figsize=(30, 30),\n",
    "        dpi=300,\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask', 'Post-processed Mask'],\n",
    "    )\n",
    "        \n",
    "    return image, mask, pred_mask, pp_pred_mask, fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c344c8-1130-49cb-b371-ca9f70bfa38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "output_path = os.path.join('inferences')\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "he_output_path = os.path.join(output_path, 'CDACS_HECR')\n",
    "os.makedirs(he_output_path, exist_ok=True)\n",
    "if_output_path = os.path.join(output_path, 'CDACS_IFCR')\n",
    "os.makedirs(if_output_path, exist_ok=True)\n",
    "\n",
    "def save_all_imgs(dataset_path, image, mask, pred, file_name, fig, save=True):\n",
    "    basename = file_name.split('.')[0]\n",
    "    \n",
    "    if save:\n",
    "        plt.imsave(os.path.join(dataset_path, f'{basename}_input.png'), image[..., 0], cmap='gray')\n",
    "        plt.imsave(os.path.join(dataset_path, f'{basename}_gt.png'), mask[..., 0], cmap='gray')\n",
    "        plt.imsave(os.path.join(dataset_path, f'{basename}_pred.png'), pred[..., 0], cmap='gray')\n",
    "\n",
    "        fig.savefig(os.path.join(dataset_path, f'{basename}_fig.png'))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702897a4-55d3-48da-8cac-624effb3c5c2",
   "metadata": {},
   "source": [
    "### Inferencing H&E dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0922818-de6f-40e2-a44d-bc779770fdb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in tqdm(he_test.iterobjs()):\n",
    "    img, mask = obj['image'], obj['segmentation_mask']\n",
    "    file_name = obj['file_name'].numpy().decode('utf-8')\n",
    "    \n",
    "    cr_mask = obj['color_region_mask']\n",
    "    image, mask, pred, pp_pred, fig = large_prediction(img, mask, cr_mask)\n",
    "    \n",
    "    save_all_imgs(he_output_path, image, mask, pp_pred, file_name, fig)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e1f41-9c50-42bb-8b48-5c70ef331748",
   "metadata": {},
   "source": [
    "### Inferencing Fluorescence dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640acf2-b2ea-4f4b-ace6-be998ea8cc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for obj in tqdm(if_test.iterobjs()):\n",
    "    img, mask = obj['image'], obj['segmentation_mask']\n",
    "    file_name = obj['file_name'].numpy().decode('utf-8')\n",
    "    \n",
    "    cr_mask = obj['color_region_mask']\n",
    "    image, mask, pred, pp_pred, fig = large_prediction(img, mask, cr_mask, patch_size)\n",
    "    \n",
    "    save_all_imgs(he_output_path, image, mask, pp_pred, file_name, fig)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
